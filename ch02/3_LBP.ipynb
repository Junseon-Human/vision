{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d9d04cb",
   "metadata": {},
   "source": [
    "## ðŸ§  LBP (Local Binary Pattern)ì´ëž€?\n",
    "\n",
    "### ðŸ“Œ ê°œë…\n",
    "- LBPëŠ” í”½ì…€ ì£¼ë³€ì˜ ë°ê¸° ë³€í™”ë¥¼ ì´ì§„ ì½”ë“œë¡œ í‘œí˜„í•´ì„œ í…ìŠ¤ì²˜(ë¬´ëŠ¬) íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ë°©ë²•.\n",
    "- ì¤‘ì‹¬ í”½ì…€ë³´ë‹¤ ë°ì€ ì´ì›ƒì€ 1, ì–´ë‘ìš´ ì´ì›ƒì€ 0ìœ¼ë¡œ í‘œì‹œ â†’ 8ë¹„íŠ¸ ì´ì§„ìˆ˜ â†’ 0~255 ê°’ìœ¼ë¡œ ë³€í™˜.\n",
    "\n",
    "### âœ… ì–¼êµ´ ì¸ì‹ì— ì í•©í•œ ì´ìœ \n",
    "- ì¡°ëª… ë³€í™”ì— ê°•í•˜ê³ , ì–¼êµ´ì˜ í…ìŠ¤ì²˜ íŠ¹ì§•ì„ ìž˜ ìž¡ì•„ëƒ„.\n",
    "- Haarë³´ë‹¤ ê°€ë³ê³  ë¹ ë¥´ë©°, ì‹¤ì‹œê°„ ì–¼êµ´ ê²€ì¶œì— ì í•©.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§© LBP ê¸°ë°˜ ì–¼êµ´ ì¸ì‹ ì „ì²´ íë¦„\n",
    "\n",
    "### ðŸŽ¯ ëª©í‘œ: ì–¼êµ´ì„ ê²€ì¶œí•˜ê³ , ëˆ„êµ¬ì¸ì§€ê¹Œì§€ ì‹ë³„í•˜ê¸°\n",
    "\n",
    "| ë‹¨ê³„ | ì„¤ëª… |\n",
    "|------|------|\n",
    "| 1ë‹¨ê³„ | `lbpcascade_frontalface.xml`ì„ ì´ìš©í•´ì„œ ì–¼êµ´ ê²€ì¶œ |\n",
    "| 2ë‹¨ê³„ | ê²€ì¶œëœ ì–¼êµ´ ì˜ì—­(ROI)ì„ ìž˜ë¼ëƒ„ |\n",
    "| 3ë‹¨ê³„ | ì–¼êµ´ ì´ë¯¸ì§€ë¥¼ í‘ë°± ë³€í™˜í•˜ê³  í¬ê¸° ì •ê·œí™” (ì˜ˆ: 100x100) |\n",
    "| 4ë‹¨ê³„ | LBP íŠ¹ì§•ì„ ì¶”ì¶œí•˜ê³ , SVMì´ë‚˜ LBPHë¡œ í•™ìŠµ |\n",
    "| 5ë‹¨ê³„ | ìƒˆë¡œìš´ ì–¼êµ´ ì´ë¯¸ì§€ê°€ ë“¤ì–´ì˜¤ë©´ ê°™ì€ ë°©ì‹ìœ¼ë¡œ íŠ¹ì§• ì¶”ì¶œ í›„, ë¶„ë¥˜ê¸°ë¡œ ì˜ˆì¸¡ |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ› ï¸ ì‚¬ìš© ê¸°ìˆ  êµ¬ì„±\n",
    "\n",
    "| í•­ëª© | ì‚¬ìš© ê¸°ìˆ  |\n",
    "|------|-----------|\n",
    "| ì–¼êµ´ ê²€ì¶œ | OpenCV LBP Cascade (`lbpcascade_frontalface.xml`) |\n",
    "| íŠ¹ì§• ì¶”ì¶œ | Local Binary Pattern (LBP) |\n",
    "| ì¸ì‹ ëª¨ë¸ | LBPHFaceRecognizer / SVM / KNN ë“± |\n",
    "| ìž…ë ¥ ë°©ì‹ | ì´ë¯¸ì§€, ì›¹ìº , CCTV ë“± |\n",
    "| ì¶œë ¥ ë°©ì‹ | ì–¼êµ´ ìœ„ì¹˜ + ì´ë¦„(í˜¹ì€ ID) ì¶œë ¥\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§ª ì˜ˆì‹œ í™œìš©\n",
    "\n",
    "- ðŸ“¸ ì¶œìž… í†µì œ: ì–¼êµ´ ì¸ì‹ìœ¼ë¡œ ë¬¸ ì—´ë¦¼\n",
    "- ðŸŽ“ ì¶œì„ ì²´í¬: ìžë™ìœ¼ë¡œ í•™ìƒ ì´ë¦„ ì¸ì‹\n",
    "- ðŸ” ê°œì¸í™” ì‹œìŠ¤í…œ: \"í™ê¸¸ë™ë‹˜, í™˜ì˜í•©ë‹ˆë‹¤\" ê°™ì€ ë©”ì‹œì§€ ì¶œë ¥\n",
    "- ðŸ“· CCTV ëª¨ë‹ˆí„°ë§: ë“±ë¡ëœ ì‚¬ëžŒë§Œ ìžë™ ì‹ë³„\n",
    "\n",
    "---\n",
    "\n",
    "## âš ï¸ ì£¼ì˜í•  ì \n",
    "\n",
    "- ì •ë©´ ì–¼êµ´ì¼ ë•Œ ì„±ëŠ¥ì´ ê°€ìž¥ ì¢‹ìŒ\n",
    "- ì–¼êµ´ ì´ë¯¸ì§€ì˜ ë°ê¸°/í¬ê¸°/í•´ìƒë„ ì •ê·œí™”ê°€ ì¤‘ìš”í•¨\n",
    "- ì¸ì‹ ì„±ëŠ¥ì€ í•™ìŠµ ë°ì´í„° ì–‘ê³¼ í’ˆì§ˆì— í¬ê²Œ ì˜í–¥ì„ ë°›ìŒ\n",
    "- LBPëŠ” ì „í†µ ë°©ì‹ì´ë¼, ê³ ì •ëœ ì¡°ëª…/í™˜ê²½ì—ì„œ ê°€ìž¥ ìž˜ ìž‘ë™í•¨\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ ëŒ€ì•ˆ ê¸°ìˆ \n",
    "\n",
    "- ðŸ” ë” ë†’ì€ ì„±ëŠ¥ì„ ì›í•œë‹¤ë©´, ë”¥ëŸ¬ë‹ ê¸°ë°˜ ê¸°ìˆ ë„ ê³ ë ¤í•´ë³¼ ìˆ˜ ìžˆìŒ\n",
    "  - ì˜ˆ: FaceNet, ArcFace, Dlib(128D), DeepFace ë“±\n",
    "  - ë‹¤ì–‘í•œ ê°ë„,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cef1f2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Cha\\1.jpg Cha\n",
      "0 [[147 140 278 278]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Cha\\2.jpg Cha\n",
      "0 [[213 183 352 352]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Cha\\3.jpg Cha\n",
      "0 [[122 201 360 360]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Cha\\4.jpg Cha\n",
      "0 [[505 100 226 226]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Cha\\5.jpg Cha\n",
      "0 [[415 158 412 412]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Cha\\cha1.jpg Cha\n",
      "0 [[285 205 452 452]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Cha\\cha2.jpg Cha\n",
      "0 ()\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Cha\\cha3.jpg Cha\n",
      "0 ()\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Cha\\cha4.jpg Cha\n",
      "0 ()\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Cha\\cha5.jpg Cha\n",
      "0 ()\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Ma\\ma1.jpg Ma\n",
      "1 [[ 71 105 472 472]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Ma\\ma2.jpg Ma\n",
      "1 [[83 46 98 98]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Ma\\ma3.jpg Ma\n",
      "1 [[294 163 439 439]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Ma\\ma4.jpg Ma\n",
      "1 ()\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Ma\\ma5.jpg Ma\n",
      "1 [[195 100 318 318]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create() # LBPHë¥¼ ì‚¬ìš©í•  ìƒˆ ë³€ìˆ˜ ìƒì„±\n",
    "\n",
    "Face_ID = -1\n",
    "prev_person_name = \"\"\n",
    "y_ID = []\n",
    "x_train = []\n",
    "\n",
    "Face_Images = os.path.join(os.getcwd(), 'Face_Images') # ì´ë¯¸ì§€ í´ë” ì§€ì •\n",
    "print(Face_Images)\n",
    "\n",
    "for root, dirs, files in os.walk(Face_Images):\n",
    "    for file in files:\n",
    "        if file.endswith('jpeg') or file.endswith('jpg') or file.endswith('png'):\n",
    "            path = os.path.join(root, file)\n",
    "            person_name = os.path.basename(root)\n",
    "            print(path, person_name)\n",
    "\n",
    "        if prev_person_name != person_name:\n",
    "            Face_ID += 1\n",
    "            prev_person_name = person_name\n",
    "\n",
    "        img = cv2.imread(path)\n",
    "        gray_iamge = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray_iamge, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "        print(Face_ID, faces)\n",
    "\n",
    "        for (x,y,w,h) in faces:\n",
    "            roi = gray_iamge[y:y+h, x:x+w]\n",
    "            x_train.append(roi)\n",
    "            y_ID.append(Face_ID)\n",
    "\n",
    "            recognizer.train(x_train, np.array(y_ID))\n",
    "            recognizer.save('face-trainner.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db708720",
   "metadata": {},
   "source": [
    "## ì¼ë¶€ ì‚¬ì§„ì„ ê²€ì¶œí•˜ì§€ ëª»í•˜ëŠ” ì´ìœ \n",
    "* print(Face_ID, faces) ì¶œë ¥ë¬¸ì—ì„œ faces ê°€ ì—†ë‹¤ëŠ”ê±´ ì–¼êµ´ ì´ë¯¸ì§€ê°€ ì¸ì‹í•˜ì§€ëª»í–ˆë‹¤ëŠ” ì˜ë¯¸\n",
    "* ê²€ì¶œí•˜ì§€ëª»í•œ ì´ë¯¸ì§€ë¥¼ ì‚´íŽ´ë³´ë©´ ì–¼êµ´ì„ ê°€ë¦¬ê³ ìžˆìŒ (ì†ìœ¼ë¡œ ì–¼êµ´ì„ ê°€ë¦¼)\n",
    "* ì–¼êµ´ì´ ì •ë©´ì´ ì•„ë‹Œ ì¸¡ë©´ìž„ (haar cascade ì˜ ë‹¨ì )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5afc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\test_list\\cha_test1.jpg\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\test_list\\cha_test2.jpg\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\test_list\\ma_test1.jpg\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\test_list\\ma_test2.jpg\n",
      "Cha 40.54975582829157\n",
      "Ma 42.30553092812899\n",
      "Cha 53.44813116389822\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "labels = ['Cha', 'Ma']\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create() # LBPHë¥¼ ì‚¬ìš©í•  ìƒˆ ë³€ìˆ˜ ìƒì„±\n",
    "recognizer.read('face-trainner.yml') # í•™ìŠµí•œ ê°’ ì½ì–´ì˜¤ê¸°\n",
    "\n",
    "image_list = []\n",
    "\n",
    "test_images = os.path.join(os.getcwd(), 'test_list')\n",
    "\n",
    "for root, dirs, files in os.walk(test_images):\n",
    "    for file in files:\n",
    "        if file.endswith('jpeg') or file.endswith('jpg') or file.endswith('png'):\n",
    "            image_path = os.path.join(test_images, file)\n",
    "            print(image_path)\n",
    "            image_list.append(cv2.imread(image_path))\n",
    "\n",
    "for img in image_list:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5)\n",
    "\n",
    "    for (x,y,w,h)in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "\n",
    "        id_, conf = recognizer.predict(roi_gray)\n",
    "        print(labels[id_], conf)\n",
    "\n",
    "        if conf >= 50:\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            name = labels[id_]\n",
    "            cv2.putText(img, name, (x,y), font, 1, (0,0,255), 2)\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0),2)\n",
    "\n",
    "    cv2.imshow('Preview', img)\n",
    "    if cv2.waitKey(0) >= 0:\n",
    "        continue\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9e9700",
   "metadata": {},
   "source": [
    "## Test_image ë„ ì •ë©´ì´ ì•„ë‹ˆë©´ ìž˜ ì˜ˆì¸¡í•˜ì§€ëª»í•¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3562943",
   "metadata": {},
   "source": [
    "# ë‹¤ë¥¸ ë°ì´í„°ë¡œ ë³µìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22306b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\\Ka\\1.jpg Ka\n",
      "0 [[147 129 356 356]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\\Ka\\2.jpg Ka\n",
      "0 [[104 133 441 441]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\\Ka\\3.jpg Ka\n",
      "0 [[272 324 480 480]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\\Ka\\4.jpg Ka\n",
      "0 [[53 57 81 81]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\\Ka\\5.jpg Ka\n",
      "0 [[109 104 239 239]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\\Win\\1.jpg Win\n",
      "1 [[430 257 467 467]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\\Win\\2.jpg Win\n",
      "1 [[89 28 95 95]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\\Win\\3.jpg Win\n",
      "1 [[224 166 352 352]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\\Win\\4.jpg Win\n",
      "1 [[87 43 65 65]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\\Win\\5.jpg Win\n",
      "1 [[204  64 132 132]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create() # LBPHë¥¼ ì‚¬ìš©í•  ìƒˆ ë³€ìˆ˜ ìƒì„±\n",
    "\n",
    "Face_ID = -1\n",
    "prev_person_name = \"\"\n",
    "y_ID = []\n",
    "x_train = []\n",
    "\n",
    "Face_Images = os.path.join(os.getcwd(), 'Face_Images2') # ì´ë¯¸ì§€ í´ë” ì§€ì •\n",
    "print(Face_Images)\n",
    "\n",
    "for root, dirs, files in os.walk(Face_Images):\n",
    "    for file in files:\n",
    "        if file.endswith('jpeg') or file.endswith('jpg') or file.endswith('png'):\n",
    "            path = os.path.join(root, file)\n",
    "            person_name = os.path.basename(root)\n",
    "            print(path, person_name)\n",
    "\n",
    "        if prev_person_name != person_name:\n",
    "            Face_ID += 1\n",
    "            prev_person_name = person_name\n",
    "\n",
    "        img = cv2.imread(path)\n",
    "        gray_iamge = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray_iamge, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "        print(Face_ID, faces)\n",
    "\n",
    "        for (x,y,w,h) in faces:\n",
    "            roi = gray_iamge[y:y+h, x:x+w]\n",
    "            x_train.append(roi)\n",
    "            y_ID.append(Face_ID)\n",
    "\n",
    "            recognizer.train(x_train, np.array(y_ID))\n",
    "            recognizer.save('face-trainner.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "448ccba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\test_list2\\ka1.jpg\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\test_list2\\ka2.jpg\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\test_list2\\win1.jpg\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\test_list2\\win2.jpg\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\test_list2\\win3.jpg\n",
      "Karina 89.16544952350635\n",
      "Winter 78.79645250793659\n",
      "Winter 88.40998433741618\n",
      "Karina 63.73462932569462\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "labels = ['Karina', 'Winter']\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create() # LBPHë¥¼ ì‚¬ìš©í•  ìƒˆ ë³€ìˆ˜ ìƒì„±\n",
    "recognizer.read('face-trainner.yml') # í•™ìŠµí•œ ê°’ ì½ì–´ì˜¤ê¸°\n",
    "\n",
    "image_list = []\n",
    "\n",
    "test_images = os.path.join(os.getcwd(), 'test_list2')\n",
    "\n",
    "for root, dirs, files in os.walk(test_images):\n",
    "    for file in files:\n",
    "        if file.endswith('jpeg') or file.endswith('jpg') or file.endswith('png'):\n",
    "            image_path = os.path.join(test_images, file)\n",
    "            print(image_path)\n",
    "            image_list.append(cv2.imread(image_path))\n",
    "\n",
    "for img in image_list:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5)\n",
    "\n",
    "    for (x,y,w,h)in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "\n",
    "        id_, conf = recognizer.predict(roi_gray)\n",
    "        print(labels[id_], conf)\n",
    "\n",
    "        if conf >= 40:\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            name = labels[id_]\n",
    "            cv2.putText(img, name, (x,y), font, 1, (0,0,255), 2)\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0),2)\n",
    "\n",
    "    cv2.imshow('Preview', img)\n",
    "    if cv2.waitKey(0) >= 0:\n",
    "        continue\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
