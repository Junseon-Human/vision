{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b5f74f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, glob, dlib\n",
    "\n",
    "age_list = ['(0, 2)','(4, 6)','(8, 12)','(15, 20)','(25, 32)','(38, 43)','(48, 53)','(60, 100)']\n",
    "gender_list = ['Male', 'Female']\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "age_net = cv2.dnn.readNetFromCaffe(\n",
    "          'models/deploy_age2.prototxt', \n",
    "          'models/age_net.caffemodel')\n",
    "gender_net = cv2.dnn.readNetFromCaffe(\n",
    "          'models/deploy_gender2.prototxt', \n",
    "          'models/gender_net.caffemodel')\n",
    "\n",
    "img_list = glob.glob('img/*.jpg')\n",
    "\n",
    "for img_path in img_list:\n",
    "  img = cv2.imread(img_path)\n",
    "  faces = detector(img)\n",
    "\n",
    "  for face in faces:\n",
    "    x1, y1, x2, y2 = face.left(), face.top(), face.right(), face.bottom()\n",
    "    face_img = img[y1:y2, x1:x2].copy()\n",
    "    blob = cv2.dnn.blobFromImage(face_img, scalefactor=1, size=(227, 227),\n",
    "      mean=(78.4263377603, 87.7689143744, 114.895847746),\n",
    "      swapRB=False, crop=False)\n",
    "    # predict gender\n",
    "    gender_net.setInput(blob)\n",
    "    gender_preds = gender_net.forward()\n",
    "    gender = gender_list[gender_preds[0].argmax()]\n",
    "    # predict age\n",
    "    age_net.setInput(blob)\n",
    "    age_preds = age_net.forward()\n",
    "    age = age_list[age_preds[0].argmax()]\n",
    "    # visualize\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (255,255,255), 2)\n",
    "    overlay_text = '%s %s' % (gender, age)\n",
    "    cv2.putText(img, overlay_text, org=(x1, y1), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "      fontScale=1, color=(0,0,0), thickness=10)\n",
    "    cv2.putText(img, overlay_text, org=(x1, y1),\n",
    "      fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255,255,255), thickness=2)\n",
    "  cv2.imshow('img', img)\n",
    "  cv2.imwrite('result/%s' % img_path.split('/')[-1], img)\n",
    "  key = cv2.waitKey(0) & 0xFF\n",
    "  if key == ord('q'):\n",
    "    break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117cb182",
   "metadata": {},
   "source": [
    "# DeepFace 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "241b65d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['img\\\\01.jpg', 'img\\\\02.jpg', 'img\\\\03.jpg', 'img\\\\04.jpg', 'img\\\\05.jpg', 'img\\\\06.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:   0%|          | 0/4 [00:00<?, ?it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 745ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  25%|██▌       | 1/4 [00:01<00:04,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 616ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  50%|█████     | 2/4 [00:02<00:02,  1.01s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 491ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion:  75%|███████▌  | 3/4 [00:02<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 190ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:03<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Action: age:   0%|          | 0/4 [00:00<?, ?it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 172ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  25%|██▌       | 1/4 [00:00<00:00,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 180ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  50%|█████     | 2/4 [00:00<00:00,  4.26it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 180ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion:  75%|███████▌  | 3/4 [00:00<00:00,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Action: age:   0%|          | 0/4 [00:00<?, ?it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 170ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  25%|██▌       | 1/4 [00:00<00:01,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 180ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  50%|█████     | 2/4 [00:00<00:00,  3.35it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 171ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion:  75%|███████▌  | 3/4 [00:00<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Action: age:   0%|          | 0/4 [00:00<?, ?it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 181ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  25%|██▌       | 1/4 [00:00<00:01,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 172ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  50%|█████     | 2/4 [00:00<00:00,  3.74it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 189ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion:  75%|███████▌  | 3/4 [00:00<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:   0%|          | 0/4 [00:00<?, ?it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 179ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  25%|██▌       | 1/4 [00:00<00:00,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 187ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  50%|█████     | 2/4 [00:00<00:00,  4.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 174ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion:  75%|███████▌  | 3/4 [00:00<00:00,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Action: age:   0%|          | 0/4 [00:00<?, ?it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 188ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  25%|██▌       | 1/4 [00:00<00:01,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 172ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  50%|█████     | 2/4 [00:00<00:00,  3.25it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 187ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion:  75%|███████▌  | 3/4 [00:00<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "from deepface.basemodels import VGGFace, OpenFace, Facenet, FbDeepFace\n",
    "import cv2, glob\n",
    "import json\n",
    "\n",
    "img_list = glob.glob('img/*.jpg')\n",
    "print(img_list)\n",
    "\n",
    "for img_path in img_list:\n",
    "    img = cv2.imread(img_path)\n",
    "    result = DeepFace.analyze(img_path, actions = ['age', 'gender', 'race', 'emotion'])\n",
    "    print(result['age'])\n",
    "    \n",
    "    gender  = result['gender']\n",
    "    age = result['age']\n",
    "    emotion = result['dominant_emotion']\n",
    "    race = result['dominant_race']\n",
    "    x1 = result['region']['x']\n",
    "    y1 = result['region']['y']\n",
    "\n",
    "    overlay_text = '%s %s %s %s' % (gender, age, emotion, race)\n",
    "    cv2.putText(img, overlay_text, org=(x1, y1), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "      fontScale=1, color=(0,0,0), thickness=10)\n",
    "    cv2.putText(img, overlay_text, org=(x1, y1),\n",
    "      fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255,255,255), thickness=2)\n",
    "    cv2.imshow('img', img)\n",
    "    cv2.imwrite('result/%s' % img_path.split('/')[-1], img)\n",
    "    key = cv2.waitKey(0) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
