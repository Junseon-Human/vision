{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d9d04cb",
   "metadata": {},
   "source": [
    "## 🧠 LBP (Local Binary Pattern)이란?\n",
    "\n",
    "### 📌 개념\n",
    "- LBP는 픽셀 주변의 밝기 변화를 이진 코드로 표현해서 텍스처(무늬) 특징을 추출하는 방법.\n",
    "- 중심 픽셀보다 밝은 이웃은 1, 어두운 이웃은 0으로 표시 → 8비트 이진수 → 0~255 값으로 변환.\n",
    "\n",
    "### ✅ 얼굴 인식에 적합한 이유\n",
    "- 조명 변화에 강하고, 얼굴의 텍스처 특징을 잘 잡아냄.\n",
    "- Haar보다 가볍고 빠르며, 실시간 얼굴 검출에 적합.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 LBP 기반 얼굴 인식 전체 흐름\n",
    "\n",
    "### 🎯 목표: 얼굴을 검출하고, 누구인지까지 식별하기\n",
    "\n",
    "| 단계 | 설명 |\n",
    "|------|------|\n",
    "| 1단계 | `lbpcascade_frontalface.xml`을 이용해서 얼굴 검출 |\n",
    "| 2단계 | 검출된 얼굴 영역(ROI)을 잘라냄 |\n",
    "| 3단계 | 얼굴 이미지를 흑백 변환하고 크기 정규화 (예: 100x100) |\n",
    "| 4단계 | LBP 특징을 추출하고, SVM이나 LBPH로 학습 |\n",
    "| 5단계 | 새로운 얼굴 이미지가 들어오면 같은 방식으로 특징 추출 후, 분류기로 예측 |\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ 사용 기술 구성\n",
    "\n",
    "| 항목 | 사용 기술 |\n",
    "|------|-----------|\n",
    "| 얼굴 검출 | OpenCV LBP Cascade (`lbpcascade_frontalface.xml`) |\n",
    "| 특징 추출 | Local Binary Pattern (LBP) |\n",
    "| 인식 모델 | LBPHFaceRecognizer / SVM / KNN 등 |\n",
    "| 입력 방식 | 이미지, 웹캠, CCTV 등 |\n",
    "| 출력 방식 | 얼굴 위치 + 이름(혹은 ID) 출력\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 예시 활용\n",
    "\n",
    "- 📸 출입 통제: 얼굴 인식으로 문 열림\n",
    "- 🎓 출석 체크: 자동으로 학생 이름 인식\n",
    "- 🔐 개인화 시스템: \"홍길동님, 환영합니다\" 같은 메시지 출력\n",
    "- 📷 CCTV 모니터링: 등록된 사람만 자동 식별\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ 주의할 점\n",
    "\n",
    "- 정면 얼굴일 때 성능이 가장 좋음\n",
    "- 얼굴 이미지의 밝기/크기/해상도 정규화가 중요함\n",
    "- 인식 성능은 학습 데이터 양과 품질에 크게 영향을 받음\n",
    "- LBP는 전통 방식이라, 고정된 조명/환경에서 가장 잘 작동함\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 대안 기술\n",
    "\n",
    "- 🔍 더 높은 성능을 원한다면, 딥러닝 기반 기술도 고려해볼 수 있음\n",
    "  - 예: FaceNet, ArcFace, Dlib(128D), DeepFace 등\n",
    "  - 다양한 각도,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cef1f2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Cha\\1.jpg Cha\n",
      "0 [[147 140 278 278]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Cha\\2.jpg Cha\n",
      "0 [[213 183 352 352]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Cha\\3.jpg Cha\n",
      "0 [[122 201 360 360]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Cha\\4.jpg Cha\n",
      "0 [[505 100 226 226]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Cha\\5.jpg Cha\n",
      "0 [[415 158 412 412]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Cha\\cha1.jpg Cha\n",
      "0 [[285 205 452 452]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Cha\\cha2.jpg Cha\n",
      "0 ()\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Cha\\cha3.jpg Cha\n",
      "0 ()\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Cha\\cha4.jpg Cha\n",
      "0 ()\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Cha\\cha5.jpg Cha\n",
      "0 ()\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Ma\\ma1.jpg Ma\n",
      "1 [[ 71 105 472 472]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Ma\\ma2.jpg Ma\n",
      "1 [[83 46 98 98]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Ma\\ma3.jpg Ma\n",
      "1 [[294 163 439 439]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Ma\\ma4.jpg Ma\n",
      "1 ()\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images\\Ma\\ma5.jpg Ma\n",
      "1 [[195 100 318 318]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create() # LBPH를 사용할 새 변수 생성\n",
    "\n",
    "Face_ID = -1\n",
    "prev_person_name = \"\"\n",
    "y_ID = []\n",
    "x_train = []\n",
    "\n",
    "Face_Images = os.path.join(os.getcwd(), 'Face_Images') # 이미지 폴더 지정\n",
    "print(Face_Images)\n",
    "\n",
    "for root, dirs, files in os.walk(Face_Images):\n",
    "    for file in files:\n",
    "        if file.endswith('jpeg') or file.endswith('jpg') or file.endswith('png'):\n",
    "            path = os.path.join(root, file)\n",
    "            person_name = os.path.basename(root)\n",
    "            print(path, person_name)\n",
    "\n",
    "        if prev_person_name != person_name:\n",
    "            Face_ID += 1\n",
    "            prev_person_name = person_name\n",
    "\n",
    "        img = cv2.imread(path)\n",
    "        gray_iamge = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray_iamge, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "        print(Face_ID, faces)\n",
    "\n",
    "        for (x,y,w,h) in faces:\n",
    "            roi = gray_iamge[y:y+h, x:x+w]\n",
    "            x_train.append(roi)\n",
    "            y_ID.append(Face_ID)\n",
    "\n",
    "            recognizer.train(x_train, np.array(y_ID))\n",
    "            recognizer.save('face-trainner.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db708720",
   "metadata": {},
   "source": [
    "## 일부 사진을 검출하지 못하는 이유\n",
    "* print(Face_ID, faces) 출력문에서 faces 가 없다는건 얼굴 이미지가 인식하지못했다는 의미\n",
    "* 검출하지못한 이미지를 살펴보면 얼굴을 가리고있음 (손으로 얼굴을 가림)\n",
    "* 얼굴이 정면이 아닌 측면임 (haar cascade 의 단점)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5afc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\test_list\\cha_test1.jpg\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\test_list\\cha_test2.jpg\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\test_list\\ma_test1.jpg\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\test_list\\ma_test2.jpg\n",
      "Cha 40.54975582829157\n",
      "Ma 42.30553092812899\n",
      "Cha 53.44813116389822\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "labels = ['Cha', 'Ma']\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create() # LBPH를 사용할 새 변수 생성\n",
    "recognizer.read('face-trainner.yml') # 학습한 값 읽어오기\n",
    "\n",
    "image_list = []\n",
    "\n",
    "test_images = os.path.join(os.getcwd(), 'test_list')\n",
    "\n",
    "for root, dirs, files in os.walk(test_images):\n",
    "    for file in files:\n",
    "        if file.endswith('jpeg') or file.endswith('jpg') or file.endswith('png'):\n",
    "            image_path = os.path.join(test_images, file)\n",
    "            print(image_path)\n",
    "            image_list.append(cv2.imread(image_path))\n",
    "\n",
    "for img in image_list:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5)\n",
    "\n",
    "    for (x,y,w,h)in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "\n",
    "        id_, conf = recognizer.predict(roi_gray)\n",
    "        print(labels[id_], conf)\n",
    "\n",
    "        if conf >= 50:\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            name = labels[id_]\n",
    "            cv2.putText(img, name, (x,y), font, 1, (0,0,255), 2)\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0),2)\n",
    "\n",
    "    cv2.imshow('Preview', img)\n",
    "    if cv2.waitKey(0) >= 0:\n",
    "        continue\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9e9700",
   "metadata": {},
   "source": [
    "## Test_image 도 정면이 아니면 잘 예측하지못함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3562943",
   "metadata": {},
   "source": [
    "# 다른 데이터로 복습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22306b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\\Ka\\1.jpg Ka\n",
      "0 [[147 129 356 356]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\\Ka\\2.jpg Ka\n",
      "0 [[104 133 441 441]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\\Ka\\3.jpg Ka\n",
      "0 [[272 324 480 480]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\\Ka\\4.jpg Ka\n",
      "0 [[53 57 81 81]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\\Ka\\5.jpg Ka\n",
      "0 [[109 104 239 239]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\\Win\\1.jpg Win\n",
      "1 [[430 257 467 467]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\\Win\\2.jpg Win\n",
      "1 [[89 28 95 95]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\\Win\\3.jpg Win\n",
      "1 [[224 166 352 352]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\\Win\\4.jpg Win\n",
      "1 [[87 43 65 65]]\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\Face_Images2\\Win\\5.jpg Win\n",
      "1 [[204  64 132 132]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create() # LBPH를 사용할 새 변수 생성\n",
    "\n",
    "Face_ID = -1\n",
    "prev_person_name = \"\"\n",
    "y_ID = []\n",
    "x_train = []\n",
    "\n",
    "Face_Images = os.path.join(os.getcwd(), 'Face_Images2') # 이미지 폴더 지정\n",
    "print(Face_Images)\n",
    "\n",
    "for root, dirs, files in os.walk(Face_Images):\n",
    "    for file in files:\n",
    "        if file.endswith('jpeg') or file.endswith('jpg') or file.endswith('png'):\n",
    "            path = os.path.join(root, file)\n",
    "            person_name = os.path.basename(root)\n",
    "            print(path, person_name)\n",
    "\n",
    "        if prev_person_name != person_name:\n",
    "            Face_ID += 1\n",
    "            prev_person_name = person_name\n",
    "\n",
    "        img = cv2.imread(path)\n",
    "        gray_iamge = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray_iamge, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "        print(Face_ID, faces)\n",
    "\n",
    "        for (x,y,w,h) in faces:\n",
    "            roi = gray_iamge[y:y+h, x:x+w]\n",
    "            x_train.append(roi)\n",
    "            y_ID.append(Face_ID)\n",
    "\n",
    "            recognizer.train(x_train, np.array(y_ID))\n",
    "            recognizer.save('face-trainner.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "448ccba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\test_list2\\ka1.jpg\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\test_list2\\ka2.jpg\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\test_list2\\win1.jpg\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\test_list2\\win2.jpg\n",
      "c:\\Users\\main\\Desktop\\vision_project\\ch02\\test_list2\\win3.jpg\n",
      "Karina 89.16544952350635\n",
      "Winter 78.79645250793659\n",
      "Winter 88.40998433741618\n",
      "Karina 63.73462932569462\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "labels = ['Karina', 'Winter']\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create() # LBPH를 사용할 새 변수 생성\n",
    "recognizer.read('face-trainner.yml') # 학습한 값 읽어오기\n",
    "\n",
    "image_list = []\n",
    "\n",
    "test_images = os.path.join(os.getcwd(), 'test_list2')\n",
    "\n",
    "for root, dirs, files in os.walk(test_images):\n",
    "    for file in files:\n",
    "        if file.endswith('jpeg') or file.endswith('jpg') or file.endswith('png'):\n",
    "            image_path = os.path.join(test_images, file)\n",
    "            print(image_path)\n",
    "            image_list.append(cv2.imread(image_path))\n",
    "\n",
    "for img in image_list:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5)\n",
    "\n",
    "    for (x,y,w,h)in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "\n",
    "        id_, conf = recognizer.predict(roi_gray)\n",
    "        print(labels[id_], conf)\n",
    "\n",
    "        if conf >= 40:\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            name = labels[id_]\n",
    "            cv2.putText(img, name, (x,y), font, 1, (0,0,255), 2)\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0),2)\n",
    "\n",
    "    cv2.imshow('Preview', img)\n",
    "    if cv2.waitKey(0) >= 0:\n",
    "        continue\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
